{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6351ec73-3c60-4342-a77a-e36440f4a57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 22:45:15,865 - __main__ - INFO - üèÅ D√©but du pipeline\n",
      "2025-05-10 22:45:15,971 - __main__ - INFO - üèÅ D√©but chargement les fichiers\n",
      "2025-05-10 22:45:15,990 - __main__ - INFO - üèÅ D√©but transformation les donn√©es\n",
      "2025-05-10 22:45:19,795 - __main__ - INFO -  ---Chargement de dim_produit dans SQL Server---\n",
      "2025-05-10 22:45:22,039 - __main__ - INFO -  ---Chargement de dim_entrepot dans SQL Server---\n",
      "2025-05-10 22:45:23,049 - __main__ - INFO -  ---Chargement de stg_commandes dans SQL Server---\n",
      "2025-05-10 22:45:24,081 - __main__ - INFO -  ---Chargement de stg_livrasion dans SQL Server---\n",
      "2025-05-10 22:45:25,075 - __main__ - INFO -  ---Chargement de stg_mouvements dans SQL Server---\n",
      "2025-05-10 22:45:25,982 - __main__ - INFO -  ---Chargement de FACT_Mouvement dans SQL Server---\n",
      "2025-05-10 22:45:26,962 - __main__ - INFO -  ---Chargement de FACT_Livraison dans SQL Server---\n",
      "2025-05-10 22:45:28,558 - __main__ - INFO -  ---Chargement de FACT_commandes dans SQL Server---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Uploading FACT_Mouvement to BigQuery ‚Üí pipeline-458019.vente.FACT_Mouvement ...\n",
      "‚úÖ Table FACT_Mouvement uploaded successfully.\n",
      "üì§ Uploading FACT_Livraison to BigQuery ‚Üí pipeline-458019.vente.FACT_Livraison ...\n",
      "‚úÖ Table FACT_Livraison uploaded successfully.\n",
      "üì§ Uploading FACT_commandes to BigQuery ‚Üí pipeline-458019.vente.FACT_commandes ...\n",
      "‚úÖ Table FACT_commandes uploaded successfully.\n",
      "üì§ Uploading dim_produit to BigQuery ‚Üí pipeline-458019.vente.dim_produit ...\n",
      "‚úÖ Table dim_produit uploaded successfully.\n",
      "üì§ Uploading dim_entrepot to BigQuery ‚Üí pipeline-458019.vente.dim_entrepot ...\n",
      "‚úÖ Table dim_entrepot uploaded successfully.\n",
      "R√©sultat transform√© :\n",
      "   col1  col2 date_chargement\n",
      "0   1.0   1.0      2025-05-10\n",
      "4   1.0   2.0      2025-05-10\n",
      "‚úÖ Test FINAL r√©ussi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 22:45:48,588 - __main__ - INFO - ‚úÖ Table dim_produit contient des donn√©es \n",
      "2025-05-10 22:45:48,703 - __main__ - INFO - ‚úÖ Table dim_entrepot contient des donn√©es \n",
      "2025-05-10 22:45:48,742 - __main__ - INFO - ‚úÖ Table stg_commandes contient des donn√©es \n",
      "2025-05-10 22:45:48,776 - __main__ - INFO - ‚úÖ Table stg_livrasion contient des donn√©es \n",
      "2025-05-10 22:45:48,900 - __main__ - INFO - ‚úÖ Table stg_mouvements contient des donn√©es \n",
      "2025-05-10 22:45:49,887 - __main__ - INFO - ‚úÖ Table FACT_Mouvement contient des donn√©es \n",
      "2025-05-10 22:45:49,918 - __main__ - INFO - ‚úÖ Table FACT_Livraison contient des donn√©es \n",
      "2025-05-10 22:45:49,960 - __main__ - INFO - ‚úÖ Table FACT_commandes contient des donn√©es \n",
      "2025-05-10 22:46:16,683 - __main__ - INFO - ‚úÖ Table BigQuery vente.FACT_Mouvement contient des donn√©es\n",
      "2025-05-10 22:46:19,072 - __main__ - INFO - ‚úÖ Table BigQuery vente.FACT_Livraison contient des donn√©es\n",
      "2025-05-10 22:46:21,234 - __main__ - INFO - ‚úÖ Table BigQuery vente.FACT_commandes contient des donn√©es\n",
      "2025-05-10 22:46:24,149 - __main__ - INFO - ‚úÖ Table BigQuery vente.dim_produit contient des donn√©es\n",
      "2025-05-10 22:46:26,731 - __main__ - INFO - ‚úÖ Table BigQuery vente.dim_entrepot contient des donn√©es\n",
      "2025-05-10 22:46:26,732 - __main__ - INFO - Test BigQuery r√©ussi - Toutes les tables contiennent des donn√©es\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "%run ./pipeline_GCP.ipynb\n",
    "\n",
    "def test_transformation_df():\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"col1\": [1, None, None, 1, 1],\n",
    "        \"col2\": [1, None, None, 1, 2]\n",
    "    })\n",
    "    \n",
    "    transformed = transformation_df(df)\n",
    "    print(\"R√©sultat transform√© :\")\n",
    "    print(transformed)\n",
    "    \n",
    "\n",
    "    assert \"date_chargement\" in transformed.columns\n",
    "    assert transformed[\"date_chargement\"].iloc[0] == date.today()\n",
    "    assert len(transformed) == 2  \n",
    "    assert pd.isna(transformed[['col1', 'col2']]).sum().sum() == 0  \n",
    "    print(\"‚úÖ Test FINAL r√©ussi\")\n",
    "\n",
    "def test_sql_server_integration():\n",
    "    \"\"\"Teste que les donn√©es sont bien stock√©es dans SQL Server\"\"\"\n",
    "\n",
    "    engine = create_sql_engine(\n",
    "        server='DESKTOP-Q8EQVSL\\\\MSSQLSERVER2022',\n",
    "        database='Fact_Commandes',\n",
    "        username='aze',\n",
    "        password='aze',\n",
    "        driver='ODBC Driver 17 for SQL Server'\n",
    "    )\n",
    "\n",
    "    tables_to_check = [\n",
    "        \"dim_produit\",\n",
    "        \"dim_entrepot\",\n",
    "        \"stg_commandes\",\n",
    "        \"stg_livrasion\",\n",
    "        \"stg_mouvements\",\n",
    "        \"FACT_Mouvement\",\n",
    "        \"FACT_Livraison\",\n",
    "        \"FACT_commandes\"\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    for table in tables_to_check:\n",
    "      try:  \n",
    "        df = pd.read_sql(f\"SELECT TOP 1 * FROM {table}\", engine)\n",
    "        if  df.empty :\n",
    "            logger.info(f\"la  Table {table} est vide\")\n",
    "        else :\n",
    "            logger.info(f\"‚úÖ Table {table} contient des donn√©es \")\n",
    "      except Exception as e:\n",
    "            logger.error(f\"‚ùå Erreur sur la table {table} : {str(e)}\")\n",
    "            raise\n",
    "\n",
    "def test_bigquery_integration():\n",
    "    \"\"\"Teste que les donn√©es sont bien stock√©es dans BigQuery\"\"\"\n",
    "\n",
    "    credential_path = r\"C:\\Users\\user\\Pipeline_09_05_2025\\credential_path\\bigquery_credentials.json\"\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "    credential_path,\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],)\n",
    "    client = bigquery.Client(credentials=credentials, project=\"pipeline-458019\")\n",
    "    \n",
    "    \n",
    "\n",
    "    tables_to_check = {\n",
    "        \"FACT_Mouvement\": \"vente\",\n",
    "        \"FACT_Livraison\": \"vente\",\n",
    "        \"FACT_commandes\": \"vente\" ,\n",
    "         \"dim_produit\" :\"vente\" ,\n",
    "         \"dim_entrepot\" :\"vente\"\n",
    "    }\n",
    "    \n",
    "    # 3. V√©rification de chaque table\n",
    "    for table, dataset in tables_to_check.items():\n",
    "        try:\n",
    "            query = f\"SELECT * FROM `pipeline-458019.{dataset}.{table}` LIMIT 1\"\n",
    "            df = client.query(query).to_dataframe()\n",
    "            assert not df.empty, f\"La table {table} est vide\"\n",
    "            logger.info(f\"‚úÖ Table BigQuery {dataset}.{table} contient des donn√©es\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Erreur sur la table {dataset}.{table} : {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    logger.info(\"Test BigQuery r√©ussi - Toutes les tables contiennent des donn√©es\")\n",
    "\n",
    "def main():\n",
    "    test_transformation_df()\n",
    "    test_sql_server_integration()\n",
    "    test_bigquery_integration()\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a4841e-6e47-4907-a3ed-ef0371395faf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

name: SQL Server to BigQuery Pipeline

on:
  workflow_dispatch:  # Permet un déclenchement manuel
  schedule:
    - cron: '0 1 * * *'  # Exécution quotidienne à 1h du matin

jobs:
  etl_pipeline:
    runs-on: windows-latest  # Utilise un runner Windows
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Install ODBC Driver
      shell: powershell
      run: |
        # Vérifie si le driver est déjà installé
        $driverName = 'ODBC Driver 17 for SQL Server'
        if (-not (Get-ItemProperty 'HKLM:\SOFTWARE\ODBC\ODBCINST.INI\ODBC Drivers' -Name $driverName -ErrorAction SilentlyContinue)) {
            Write-Host "Installing $driverName..."
            Invoke-WebRequest -Uri 'https://go.microsoft.com/fwlink/?linkid=2202930' -OutFile 'msodbcsql.msi'
            Start-Process msiexec.exe -Wait -ArgumentList '/i msodbcsql.msi /quiet /norestart IACCEPTMSODBCSQLLICENSETERMS=YES'
            Remove-Item msodbcsql.msi
        }
        Get-ItemProperty 'HKLM:\SOFTWARE\ODBC\ODBCINST.INI\ODBC Drivers' | Format-List

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas pyodbc google-cloud-bigquery python-dotenv

    - name: Configure Google Cloud credentials
      uses: google-github-actions/auth@v1
      with:
        credentials_json: ${{ secrets.GOOGLE_CREDENTIALS_JSON }}

    - name: Set up environment variables
      run: |
        echo "SQL_SERVER=${{ secrets.SQL_SERVER }}" >> $env:GITHUB_ENV
        echo "SQL_DATABASE=${{ secrets.SQL_DATABASE }}" >> $env:GITHUB_ENV
        echo "SQL_USERNAME=${{ secrets.SQL_USERNAME }}" >> $env:GITHUB_ENV
        echo "SQL_PASSWORD=${{ secrets.SQL_PASSWORD }}" >> $env:GITHUB_ENV
        echo "SQL_DRIVER=ODBC Driver 17 for SQL Server" >> $env:GITHUB_ENV
        echo "GCP_PROJECT_ID=${{ secrets.GCP_PROJECT_ID }}" >> $env:GITHUB_ENV
        echo "BQ_DATASET_ID=${{ secrets.BQ_DATASET_ID }}" >> $env:GITHUB_ENV
        echo "DATA_BASE_PATH=./data" >> $env:GITHUB_ENV
      shell: powershell

    - name: Create data directory
      run: |
        mkdir data
        # Copiez vos fichiers CSV dans le dossier data si nécessaire
        # ou ajoutez une étape pour les télécharger

    - name: Debug environment
      run: |
        echo "Environment variables:"
        echo "SQL_SERVER: $env:SQL_SERVER"
        echo "SQL_DATABASE: $env:SQL_DATABASE"
        echo "SQL_DRIVER: $env:SQL_DRIVER"
        echo "DATA_BASE_PATH: $env:DATA_BASE_PATH"
        python -c "import pyodbc; print('Available ODBC drivers:', pyodbc.drivers())"
      shell: powershell

    - name: Run ETL pipeline
      run: python Script_python/pipeline_GCP.py
      shell: powershell
